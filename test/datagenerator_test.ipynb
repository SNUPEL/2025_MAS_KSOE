{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-17T07:54:39.638597Z",
     "start_time": "2025-07-17T07:54:39.597299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self,\n",
    "                 block_data_path,\n",
    "                 bay_data_path,\n",
    "                 num_blocks=50,\n",
    "                 time_horizon=30,\n",
    "                 iat_avg=0.1,\n",
    "                 buffer_avg=1.5,\n",
    "                 weight_factor=0.7,\n",
    "                 fix_time_horizon=False):\n",
    "\n",
    "        self.block_data_path = block_data_path\n",
    "        self.bay_data_path = bay_data_path\n",
    "        self.num_blocks = num_blocks\n",
    "        self.time_horizon = time_horizon\n",
    "        self.iat_avg = iat_avg\n",
    "        self.buffer_avg = buffer_avg\n",
    "        self.weight_factor = weight_factor\n",
    "        self.fix_time_horizon = fix_time_horizon\n",
    "\n",
    "        self.df_bay = pd.read_excel(bay_data_path, sheet_name=\"bays\", engine=\"openpyxl\")\n",
    "        self.df_count = pd.read_excel(block_data_path, sheet_name=\"count\", engine=\"openpyxl\") # 그룹 개수에 대한 데이터프레임\n",
    "        self.df_length = pd.read_excel(block_data_path, sheet_name=\"length\", engine=\"openpyxl\")  # 그룹 별 블록 길이 분포에 대한 데이터프레임\n",
    "        self.df_breadth = pd.read_excel(block_data_path, sheet_name=\"breadth\", engine=\"openpyxl\")  # 그룹 별 블록 폭 분포에 대한 데이터프레임\n",
    "        self.df_height = pd.read_excel(block_data_path, sheet_name=\"height\", engine=\"openpyxl\")  # 그룹 별 블록 높이 분포에 대한 데이터프레임\n",
    "        self.df_weight =  pd.read_excel(block_data_path, sheet_name=\"weight\", engine=\"openpyxl\") # 그룹 별 중량 모델에 대한 데이터프레임\n",
    "        self.df_h1 = pd.read_excel(block_data_path, sheet_name=\"h1\", engine=\"openpyxl\") # 그룹 별 H01 모델에 대한 데이터프레임\n",
    "        self.df_h2 = pd.read_excel(block_data_path, sheet_name=\"h2\", engine=\"openpyxl\") # 그룹 별 H02 모델에 대한 데이터프레임\n",
    "        self.df_duration = pd.read_excel(block_data_path, sheet_name=\"duration\", engine=\"openpyxl\") # 그룹 별 duration 모델에 대한 데이터프레임\n",
    "        self.df_sample = pd.read_excel(block_data_path, sheet_name=\"sample\", engine=\"openpyxl\")\n",
    "\n",
    "    def generate_group(self):  # 그룹을 선택한 후 선종과 블록 종류로 나누기 위한 함수\n",
    "        # 그룹을 랜덤으로 선택->선종과 블록 타입으로 분리\n",
    "        group_code = np.random.choice(self.df_count['group'], p=self.df_count['proportion'])\n",
    "        ship_type = group_code[0:2]\n",
    "        block_type = group_code[-1]\n",
    "\n",
    "        return group_code, ship_type, block_type\n",
    "\n",
    "    def generate_process(self, group_code):         # 공종 명칭 생성 함수, 공정이 나오는 비율에 맞춰서 데이터 생성\n",
    "        df_process_count = self.df_count[self.df_count['group'] == group_code]\n",
    "\n",
    "        # 각 count 값을 올바르게 추출\n",
    "        count = df_process_count['count'].values[0]\n",
    "        panel_proportion = df_process_count['panel_count'].values[0] / count\n",
    "        curve_proportion = df_process_count['curve_count'].values[0] / count\n",
    "        big_proportion = df_process_count['big_count'].values[0] / count\n",
    "        final_proportion = df_process_count['final_count'].values[0] / count\n",
    "\n",
    "        proportion_list = [panel_proportion, curve_proportion, big_proportion, final_proportion]\n",
    "        process_type = np.random.choice(['평중조', '곡중조', '대조중조', 'Final조립'], p=proportion_list)\n",
    "\n",
    "        return process_type\n",
    "\n",
    "    def generate_property(self, group_code, process_type, property='L'):\n",
    "        if property == 'L':\n",
    "            df_property = self.df_length.copy(deep=False)\n",
    "        elif property == 'B':\n",
    "            df_property = self.df_breadth.copy(deep=False)\n",
    "        elif property == 'H':\n",
    "            df_property = self.df_height.copy(deep=False)\n",
    "        else:\n",
    "            raise Exception(\"Invalid property\")\n",
    "\n",
    "        df_property['best_params'] = df_property['best_params'].apply(ast.literal_eval)\n",
    "        df_property = df_property[(df_property['group'] == group_code)\n",
    "                                  & (df_property['process_type'] == process_type)]\n",
    "        best_distribution_name = df_property['best_distribution_name'].values[0]\n",
    "        best_params = df_property['best_params'].values[0]\n",
    "        min_value = df_property['min'].values[0]\n",
    "        max_value = df_property['max'].values[0]\n",
    "\n",
    "        if best_distribution_name == 'cauchy':\n",
    "            property_value = stats.cauchy.rvs(*best_params)\n",
    "        elif best_distribution_name == 'expon':\n",
    "            property_value = stats.expon.rvs(*best_params)\n",
    "        elif best_distribution_name == 'gamma':\n",
    "            property_value = stats.gamma.rvs(*best_params)\n",
    "        elif best_distribution_name == 'norm':\n",
    "            property_value = stats.norm.rvs(*best_params)\n",
    "        elif best_distribution_name == 'exponpow':\n",
    "            property_value = stats.exponpow.rvs(*best_params)\n",
    "        elif best_distribution_name == 'lognorm':\n",
    "            property_value = stats.lognorm.rvs(*best_params)\n",
    "        elif best_distribution_name == 'powerlaw':\n",
    "            property_value = stats.powerlaw.rvs(*best_params)\n",
    "        elif best_distribution_name == 'reyleigh':\n",
    "            property_value = stats.reyleigh.rvs(*best_params)\n",
    "        elif best_distribution_name == 'uniform':\n",
    "            property_value = stats.uniform.rvs(*best_params)\n",
    "        else:\n",
    "            property_value = 0\n",
    "            # raise Exception(\"Invalid distriution\")\n",
    "\n",
    "        if property_value > max_value:\n",
    "            property_value = max_value\n",
    "        elif property_value < min_value:\n",
    "            property_value = min_value\n",
    "\n",
    "        property_value = np.floor(property_value * 10) / 10\n",
    "\n",
    "        return property_value\n",
    "\n",
    "    def generate_weight(self, group_code, process_type, length, breadth, height):\n",
    "        if group_code not in ['CN_T', 'LN_D', 'VL_D']:\n",
    "            df_weight = self.df_weight[self.df_weight['group'] == group_code]\n",
    "        else:\n",
    "            if group_code == 'CN_T': # CN_T: CN_D의 모델 사용\n",
    "                df_weight = self.df_weight[self.df_weight['group'] == 'CN_D']\n",
    "            elif group_code == 'LN_D': # LN_D: LN_E의 모델 사용\n",
    "                df_weight = self.df_weight[self.df_weight['group'] == 'LN_E']\n",
    "            elif group_code == 'VL_D': # VL_D: VL_B의 모델 사용\n",
    "                df_weight = self.df_weight[self.df_weight['group'] == 'VL_B']\n",
    "\n",
    "        reg_coef = df_weight['coef'].values[0]\n",
    "        noise = df_weight['std'].values[0]\n",
    "        min_value = df_weight['min'].values[0]\n",
    "        max_value = df_weight['max'].values[0]\n",
    "\n",
    "        volume = length * breadth * height\n",
    "\n",
    "        if process_type == 'Final조립':\n",
    "            weight = reg_coef * volume + np.random.normal(0, noise)\n",
    "        else: # 중조 무게 피팅\n",
    "            weight = reg_coef * volume * self.weight_factor + np.random.normal(0, noise)\n",
    "\n",
    "        if weight < min_value:\n",
    "            weight = min_value\n",
    "        elif weight > max_value:\n",
    "            weight = max_value\n",
    "\n",
    "        weight = np.int64(weight)\n",
    "\n",
    "        return weight\n",
    "\n",
    "    def generate_workload_h1(self, group_code, length, breadth):\n",
    "        df_h1 = self.df_h1[self.df_h1['group'] == group_code]\n",
    "\n",
    "        reg_coef = [df_h1['coef_0'].values[0],\n",
    "                    df_h1['coef_1'].values[0],\n",
    "                    df_h1['coef_2'].values[0]]\n",
    "        noise = df_h1['std'].values[0]\n",
    "        min_value = df_h1['min'].values[0]\n",
    "\n",
    "        workload_h1 = (reg_coef[0] * length + reg_coef[1] * breadth\n",
    "                       + reg_coef[2] * (length * breadth) + np.random.normal(0, noise))\n",
    "\n",
    "        if workload_h1 < min_value:\n",
    "            workload_h1 = min_value\n",
    "\n",
    "        workload_h1 = np.int64(workload_h1)\n",
    "\n",
    "        return workload_h1\n",
    "\n",
    "    def generate_workload_h2(self, group_code, workload_h1):\n",
    "        df_h2 = self.df_h2[self.df_h2['group'] == group_code]\n",
    "\n",
    "        reg_coef = df_h2['coef'].values[0]\n",
    "        noise = df_h2['std'].values[0]\n",
    "        min_value = df_h2['min'].values[0]\n",
    "        max_value = df_h2['max'].values[0]\n",
    "\n",
    "        workload_h2 = reg_coef * workload_h1 + np.random.normal(0, noise)\n",
    "\n",
    "        if workload_h2 < min_value:\n",
    "            workload_h2 = min_value\n",
    "        elif workload_h2 > max_value:\n",
    "            workload_h2 = max_value\n",
    "\n",
    "        workload_h2 = np.int64(workload_h2)\n",
    "\n",
    "        return workload_h2\n",
    "\n",
    "    def generate_duration(self, group_code, workload_h1, workload_h2, weight):\n",
    "        df_duration = self.df_duration[self.df_duration['group'] == group_code]\n",
    "\n",
    "        reg_coef = [df_duration['coef_0'].values[0],\n",
    "                    df_duration['coef_1'].values[0],\n",
    "                    df_duration['coef_2'].values[0]]\n",
    "        noise = df_duration['std'].values[0]\n",
    "        min_value = df_duration['min'].values[0]\n",
    "\n",
    "        duration = (reg_coef[0] * workload_h1 + reg_coef[1] * workload_h2\n",
    "                    + reg_coef[2] * weight + np.random.normal(0, noise))\n",
    "\n",
    "        if duration < min_value:\n",
    "            duration = min_value\n",
    "\n",
    "        duration = np.int64(duration)\n",
    "\n",
    "        return duration\n",
    "\n",
    "    def calculate_buffer(self, process_type):  # column에 들어가는 값은 아님\n",
    "        if process_type == 'Final조립':\n",
    "            buffer = 2\n",
    "        else:\n",
    "            p = 1 / (1 + self.buffer_avg)\n",
    "            buffer = stats.geom.rvs(p) - 1\n",
    "\n",
    "        return buffer\n",
    "\n",
    "    def check_eligibility(self, breadth, height, weight):\n",
    "        df_eligible_bay = self.df_bay[(breadth <= self.df_bay[\"block_breadth\"]) &\n",
    "                                      (height <= self.df_bay[\"block_height\"]) &\n",
    "                                      (weight <= self.df_bay[\"block_weight\"])]\n",
    "\n",
    "        if len(df_eligible_bay) == 0:\n",
    "            df_weight = self.df_bay[\"block_weight\"][(breadth <= self.df_bay[\"block_breadth\"]) &\n",
    "                                                    (height <= self.df_bay[\"block_height\"])]\n",
    "\n",
    "            weight = df_weight.max()\n",
    "\n",
    "        return breadth, height, weight\n",
    "\n",
    "    def generate(self, file_path=None):\n",
    "        columns = [\"block_name\", \"block_id\", \"ship_type\", \"block_type\", \"process_type\",\n",
    "                   \"length\", \"breadth\", \"height\", \"weight\", \"workload_h1\", \"workload_h2\",\n",
    "                   \"start_date\", \"duration\", \"due_date\", \"pre_buffer\", \"post_buffer\"]\n",
    "\n",
    "        df_blocks = []\n",
    "\n",
    "        num_blocks = 0\n",
    "        start_date = 0\n",
    "\n",
    "        while True:\n",
    "            if self.fix_time_horizon:\n",
    "                if start_date >= self.time_horizon:\n",
    "                    flag = True\n",
    "                    del df_blocks[-1]\n",
    "                else:\n",
    "                    flag = False\n",
    "            else:\n",
    "                if num_blocks == self.num_blocks:\n",
    "                    flag = True\n",
    "                else:\n",
    "                    flag = False\n",
    "\n",
    "            if flag:\n",
    "                break\n",
    "\n",
    "            name = \"J-%d\" % num_blocks\n",
    "            id = num_blocks\n",
    "\n",
    "            # 데이터 생성\n",
    "            group_code, ship_type, block_type = self.generate_group()\n",
    "            process_type = self.generate_process(group_code)\n",
    "\n",
    "            if num_blocks == 0:\n",
    "                start_date = 0  # 첫번째 착수일은 0으로 고정\n",
    "            else:\n",
    "                p = 1 / (1 + self.iat_avg)\n",
    "                start_date += stats.geom.rvs(p) - 1  # 이전 착수일에 interval을 더하는 형식으로 계산\n",
    "\n",
    "            if group_code not in ['BC_A', 'BC_S', 'PT_D', 'PT_L', 'PT_R',\n",
    "                                  'VL_A', 'VL_B', 'VL_D', 'VL_E', 'VL_F', 'VL_S']:\n",
    "\n",
    "                length = self.generate_property(group_code, process_type, 'L')\n",
    "                breadth = self.generate_property(group_code, process_type, 'B')\n",
    "                height = self.generate_property(group_code, process_type, 'H')\n",
    "\n",
    "                weight = self.generate_weight(group_code, process_type, length, breadth, height)\n",
    "\n",
    "                breadth, height, weight = self.check_eligibility(breadth, height, weight)\n",
    "\n",
    "                workload_h1 = self.generate_workload_h1(group_code, length, breadth)\n",
    "                workload_h2 = self.generate_workload_h2(group_code, workload_h1)\n",
    "\n",
    "                duration = self.generate_duration(group_code, workload_h1, workload_h2, weight)\n",
    "\n",
    "            else: # 샘플링된 그룹에 대한 처리, 한 행의 데이터를 그대로 가져오는 식으로 구현\n",
    "                df_sample = self.df_sample[self.df_sample['group'] == group_code]\n",
    "                df_sample = df_sample[df_sample['process_type'] == process_type]\n",
    "                df_sample.reset_index(inplace=True)\n",
    "                idx = np.random.choice(range(df_sample.shape[0]))\n",
    "\n",
    "                length = df_sample.loc[idx, 'length']\n",
    "                breadth = df_sample.loc[idx, 'breadth']\n",
    "                height = df_sample.loc[idx, 'height']\n",
    "\n",
    "                if process_type == 'Final조립':\n",
    "                    weight = df_sample.loc[idx, 'weight']\n",
    "                else:\n",
    "                    weight = self.generate_weight(group_code, process_type, length, breadth, height)\n",
    "\n",
    "                workload_h1 = df_sample.loc[idx, 'workload_h1']\n",
    "                workload_h2 = df_sample.loc[idx, 'workload_h2']\n",
    "\n",
    "                duration = df_sample.loc[idx, 'duration']\n",
    "\n",
    "            pre_buffer = 5\n",
    "            post_buffer = self.calculate_buffer(process_type)\n",
    "\n",
    "            due_date = start_date + duration + post_buffer - 1\n",
    "\n",
    "            row = [name, id, ship_type, block_type, process_type,\n",
    "                   length, breadth, height, weight, workload_h1, workload_h2,\n",
    "                   start_date, duration, due_date, pre_buffer, post_buffer]\n",
    "\n",
    "            df_blocks.append(row)\n",
    "            num_blocks += 1\n",
    "\n",
    "        df_blocks = pd.DataFrame(df_blocks, columns=columns)\n",
    "\n",
    "        if file_path is not None:\n",
    "            writer = pd.ExcelWriter(file_path)\n",
    "            df_blocks.to_excel(writer, sheet_name=\"blocks\", index=False)\n",
    "            writer.close()\n",
    "\n",
    "        return df_blocks\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     import os\n",
    "#\n",
    "#     # validation data generation\n",
    "#     block_data_path = \"../input/configurations/block_data.xlsx\"\n",
    "#     bay_data_path = \"../input/configurations/bay_data.xlsx\"\n",
    "#     # num_blocks = 50\n",
    "#     time_horizon = 30\n",
    "#\n",
    "#     data_src = DataGenerator(block_data_path,\n",
    "#                              bay_data_path,\n",
    "#                              time_horizon=time_horizon,\n",
    "#                              fix_time_horizon=True)\n",
    "#\n",
    "#     file_dir = \"../input/validation/\"\n",
    "#     if not os.path.exists(file_dir):\n",
    "#         os.makedirs(file_dir)\n",
    "#\n",
    "#     iteration = 20\n",
    "#     for i in range(1, iteration + 1):\n",
    "#         file_path = file_dir + \"instance-{0}.xlsx\".format(i)\n",
    "#         df_blocks = data_src.generate(file_path)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:13:46.637416Z",
     "start_time": "2025-07-17T08:13:46.379268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "block_data_path = \"../input/configurations/block_data.xlsx\"\n",
    "bay_data_path = \"../input/configurations/bay_data.xlsx\"\n",
    "data_gen = DataGenerator(block_data_path, bay_data_path)\n",
    "weight_ex = data_gen.generate_weight('CN_S', 'Final조립', 21.5, 22.5, 11.5)"
   ],
   "id": "513468e4037de504",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:13:47.476690Z",
     "start_time": "2025-07-17T08:13:47.469904Z"
    }
   },
   "cell_type": "code",
   "source": "weight_ex",
   "id": "dde43ed883dc2ff1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:14:04.792054Z",
     "start_time": "2025-07-17T08:14:04.783395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "H01_ex = data_gen.generate_workload_h1('CN_S', 21.5, 22.5)\n",
    "H02_ex = data_gen.generate_workload_h2('CN_S', H01_ex)"
   ],
   "id": "6cac5eb0c5ef7f7c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:14:05.977038Z",
     "start_time": "2025-07-17T08:14:05.968380Z"
    }
   },
   "cell_type": "code",
   "source": "H01_ex",
   "id": "1c2f31211f8b4567",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:14:06.886727Z",
     "start_time": "2025-07-17T08:14:06.877683Z"
    }
   },
   "cell_type": "code",
   "source": "H02_ex",
   "id": "c9f55eb9401fcc57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1556"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:14:08.012406Z",
     "start_time": "2025-07-17T08:14:08.005115Z"
    }
   },
   "cell_type": "code",
   "source": "duration_ex = data_gen.generate_duration('CN_S', H01_ex, H02_ex, weight_ex)",
   "id": "6a3bd6c7b0260fe",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:14:10.717889Z",
     "start_time": "2025-07-17T08:14:10.708261Z"
    }
   },
   "cell_type": "code",
   "source": "duration_ex",
   "id": "9a46f1f988f5147f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3c17cf4cfd7a7f5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
